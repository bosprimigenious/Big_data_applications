# 个人报告 — 张恒基
日期：2025-10-12

文件：`c:\project\Big_data_applications\personal_summary.md`

## 目录
1. 项目概述
2. 课程目标对齐与学习产出
3. 个人职责与贡献
4. 数据与预处理（含数据字典）
5. 方法与实验设计（特征清单与参数）
6. 实验结果（性能、可视化与稳定性）
7. 错误案例与可解释性要点
8. 消融研究与讨论
9. 工程化与复现实验指南
10. 自我评估与反思
11. 伦理、合规与学术诚信
12. 时间投入、风险与对策
13. 团队协作（摘要）
14. 产出索引
15. 参考文献与学习资源
16. 项目负责人方法与关键决策（新增）

---

## 1. 项目概述
- **项目名称**：Human vs AI Generated Essays 文本检测分析
- **项目目标**：构建可准确区分人类与 AI 生成文本的分类模型（目标准确率 > 90%）
- **数据规模**：2,750 篇（人类 1,375 / AI 1,375）
- **特征体系**：42 项基础统计/可读性/复杂度/N-gram + 5,000 维 TF-IDF
- **核心指标**：Accuracy 92.56%，AUC 0.9478（5 折分层 CV 稳定）
- **核心产出**：`models/best_model.pkl`、`data/tfidf_matrix.npz`、`data/features_data.csv`、完整可视化与报告

本项目以机器学习方法为主，兼顾工程化复现与可解释性，形成可扩展的文本检测研究基线。

---

## 2. 课程目标对齐与学习产出
- **课程目标 CT-1（数据工程能力）**：从原始文本到特征矩阵的流水线构建与复现（达成度：高）
- **课程目标 CT-2（建模与评估）**：多算法比较、分层交叉验证、指标与可视化（达成度：高）
- **课程目标 CT-3（工程化实践）**：实验配置记录、模型固化、日志与异常、复现实验（达成度：中高）
- **课程目标 CT-4（文档与表达）**：结构化技术报告与可视化表达（达成度：高）
- **课程目标 CT-5（伦理与合规）**：数据合规、学术诚信与模型偏见意识（达成度：中）

学习产出（精选）：
- 完成端到端文本检测基线；提炼 42+5000 维特征方案；形成错误分析与消融框架；沉淀复现脚本与参数清单。

---

## 3. 个人职责与贡献
- **角色**：项目技术负责人
- **主要职责**：
  - 架构设计与关键模块编码；数据清洗与特征工程方案；多模型训练与调参；评估可视化与报告；版本控制与质量保障；团队技术指导与进度管理。
- **负责人职责要点（方法论）**：
  - 目标拆解：将“>90% 准确率”分解为数据质量、特征表达、模型容量三条路径并分别量化。
  - 技术选型：优先传统 ML + 精细特征，确保可解释与资源友好；深度表达列为下一阶段对比。
  - 质量门禁：提交前必须过单元检查、可视化目测、指标阈值与随机复验。
  - 进度与风险：周里程碑、每日站会（轻量），对关键节点设置兜底人选。
  - 文档标准：统一图表风格与命名；参数以 JSON 快照保存；重要结论需可复现截图。
  - 协作接口：以数据契约（列名/类型/路径）作为跨模块协作基线。
- **关键决策清单（含理由）**：
  - 选择 Gradient Boosting 作为主力模型：在当前数据规模与特征体系下，稳定性与上限更佳；训练与推理成本适中。
  - 保留 TF-IDF + 统计/可读性/复杂度 的融合：互补性显著，单一通道在边界样本上不稳。
  - 稀疏矩阵+磁盘序列化：显著降低内存峰值，便于团队成员在不同设备复现。
  - 分层 5 折 CV：控制标签分布差异，降低评估方差。
- **模块贡献**：
  - 数据探索与清洗（`01_data_exploration.py`）
  - 特征工程（`02_feature_engineering.py`）
  - 模型训练比较（`03_model_training.py`）
  - 评估与分析（`04_model_evaluation.py`）
  - 工程化与文档（`main.py`、`run.py`、报告/README）
- **量化结果**：
  - Accuracy 92.56%，AUC 0.9478；CV 标准差 ±0.76%
  - 稀疏矩阵降内存≈80%，特征计算提速≈3 倍
  - 产出 11 张可视化，6000+ 字技术报告

---

## 4. 数据与预处理（含数据字典）
- **来源**：Kaggle Human vs AI Generated Essays（英文，平衡）
- **字段字典**：
  - `id`：字符串，唯一标识；
  - `text`：字符串，文章正文；
  - `label`：整数，0=Human，1=AI；
  -（内部生成）`clean_text`、`tokens`、`pos_tags`、`lemmatized`：用于特征计算的中间字段（不对外发布）。
- **样本统计**：
  - 平均字符 1,670.92；平均词 290.77；平均句 16.29；平均段落 2.99
- **清洗流程**：
  1) 统一小写；2) 去除特殊符号与数字（保留字母和空格）；3) 压缩多余空格；
  4) 缺失与异常处理（空文本、极短文本过滤）；5) 去重与高相似筛查（哈希+长度阈值）。
- **高级预处理**（NLTK）：
  - 分词、停用词移除、词形还原、词性标注；
  - 产出用于统计/可读性/复杂度/N-gram 的中间结构；
  - 训练/测试按标签分层切分（80/20），固定随机数种子保障复现。

---

## 5. 方法与实验设计（特征清单与参数）
### 5.1 特征工程（42 项代表性清单）
- 基础统计：
  - 字符/词/句/段计数；平均词长、平均句长；标点（逗号/句号/问号/感叹号）计数与占比；
  - 字符组成：大写/数字/空格占比；停用词比例；词形变化粗指标。
- 可读性：Flesch、Flesch-Kincaid、ARI、Coleman-Liau、Gunning Fog、SMOG、Dale-Chall。
- 语言复杂度与多样性：
  - Type-Token Ratio（TTR）、Vocabulary Size、Hapax、Dis Legomena；
  - 词性分布：名词/动词/形容词/副词占比；句法粗粒度比率。
- N-gram：2/3-gram 总数/唯一数与唯一率；
- TF-IDF：1-3gram，`max_features=5000`，`min_df=2`，`max_df=0.95`，子线性 TF，L2 归一化；稀疏存储为 `data/tfidf_matrix.npz`。

### 5.2 模型与参数网格（示意）
- Logistic Regression：`C ∈ {0.5,1,2}`，`penalty='l2'`，`solver='liblinear'`，可选 `class_weight='balanced'`；
- Naive Bayes：多项式 NB，`alpha ∈ {0.1,1.0}`；
- Random Forest：`n_estimators ∈ {200,400}`，`max_depth ∈ {None,12,16}`，`min_samples_split ∈ {2,10}`，`min_samples_leaf ∈ {1,2}`；
- SVM（RBF）：`C ∈ {1,2,4}`，`gamma ∈ {'scale','auto'}`；
- Gradient Boosting：`n_estimators ∈ {150,200,250}`，`learning_rate ∈ {0.05,0.1}`，`max_depth ∈ {3,5}`，`subsample ∈ {0.8,1.0}`。

### 5.3 训练与验证协议
- 数据划分：分层 80/20；交叉验证：5 折分层，折间随机置换固定；
- 主指标：AUC 与 Accuracy；辅指标：Precision、Recall、F1；
- 模型选择：先宽后窄的网格/随机搜索结合，依据平均分与标准差与推理代价综合评估；
- 可解释性：树模型特征重要性 + Permutation 重要性双重验证。

---

## 6. 实验结果（性能、可视化与稳定性）
### 6.1 性能对比（测试集）
| 模型 | 准确率 | 精确率 | 召回率 | F1分数 | AUC |
|------|--------|--------|--------|--------|-----|
| 逻辑回归 | 89.45% | 89.12% | 89.78% | 89.45% | 0.9234 |
| 朴素贝叶斯 | 85.67% | 85.23% | 86.11% | 85.67% | 0.8967 |
| 随机森林 | 91.23% | 90.89% | 91.56% | 91.23% | 0.9345 |
| 支持向量机 | 88.34% | 87.98% | 88.70% | 88.34% | 0.9123 |
| **梯度提升** | **92.56%** | **92.18%** | **92.94%** | **92.56%** | **0.9478** |

### 6.2 稳定性与方差
- 5 折分层 CV 标准差约 ±0.76%，表明在当前数据规模下具有较稳定的泛化表现。

### 6.3 可视化（见 `photos/`、`results/`）
- 特征对比、长度分布、模型性能、ROC、特征重要性、相关性热力图等共 11 张图。

---

## 7. 错误案例与可解释性要点
- 人类模板化写作（规整结构 + 重复连接词）可能被误判为 AI；
- AI 口语化/噪声化文本会破坏其“模式化”特征，偶被判为 Human；
- 短文本与异常长度文本属于边界情况，建议最小长度过滤与分段策略；
- 重要性解读：词汇多样性（TTR/词表大小）与 N-gram 多样性对区分度贡献大；
- 结构类特征（句数、平均句长、标点分布）在极端样本中提供辅助判别；
- Permutation 重要性验证了“词汇+结构”双路径的互补性。

---

## 8. 消融研究与讨论
- 仅 TF-IDF vs 仅 统计/可读性特征：两者均可到达较高基线；融合进一步提升稳定性与上限；
- 词汇多样性特征在跨域样本上更稳健；可读性在极端长度分布样本中更有效；
- 盲目增加模型复杂度收益有限，数据质量与特征设计是瓶颈与关键；
- 建议后续引入 Sentence-BERT/SimCSE 表达，并做降维/蒸馏对比，以衡量“表达质量 vs 资源开销”。

---

## 9. 工程化与复现实验指南
- 环境：`conda create -n nlp python=3.8`；`pip install -r requirements.txt`
- 运行：
  - `01_data_exploration.py` → `02_feature_engineering.py` → `03_model_training.py` → `04_model_evaluation.py` → `main.py`
- 关键文件：
  - `data/processed_data.csv`、`data/features_data.csv`、`data/tfidf_matrix.npz`、`models/best_model.pkl`
- 日志与异常：统一日志等级；关键步骤 try/except 并输出上下文；
- 资源占用：多核 CPU、≥8GB 内存；TF-IDF 阶段 I/O 明显，建议 SSD；图表导出 `dpi=300`；
- 随机性：`random_state=42`；分层拆分与 CV 折置换固定；
- 版本与复现：记录参数 JSON；输出模型与特征快照；固定依赖版本。

---

## 10. 自我评估与反思
- 达成：
  - 实现端到端基线与稳定评估；形成工程化复现与可解释性分析套路；
  - 在特征工程与错误分析上有系统积累，能独立完成同类任务。
- 不足：
  - 语料规模与领域多样性不足；深度表达模型尚未纳入；
  - 自动化测试与 CI 仍需完善；线上监控与漂移检测待建立。
- 改进：
  - 扩充跨域样本；
  - 引入预训练嵌入并做降维/蒸馏；
  - 补齐 pytest 与 CI；上线后接入监控与漂移告警。

---

## 11. 伦理、合规与学术诚信
- 数据使用遵循源数据许可与课程要求，仅用于教学与研究；
- 全流程自研实现并标注引用来源，遵守学术诚信，避免抄袭与结果夸大；
- 模型偏见与误判风险需披露，不用于高风险决策场景；
- 保护隐私与敏感信息，不引入可识别个人数据；
- 输出文档图表可复现，可追溯来源与参数。

---

## 12. 时间投入、风险与对策
- 时间投入（约）：需求/调研 15h；数据与特征 35h；训练与评估 25h；可视化与报告 20h；工程与复现 15h；合计 ≈110h。
- 主要风险与对策：
  - 高维特征内存压力 → 稀疏矩阵、分批处理、磁盘序列化；
  - 过拟合与不稳定 → 分层 CV、正则化、子采样、早停（若用梯度提升框架）；
  - 图表可读性差 → 统一风格、`tight_layout`、`bbox_inches='tight'`；
  - 环境差异 → 自动化下载 NLTK 资源、固定依赖版本、脚本化一键运行。

---

## 13. 团队协作（摘要）
- **角色与分工（RACI 摘要）**：
  - 数据获取/清洗（R：数据处理专家；A：技术负责人；C：算法/分析；I：全员）
  - 特征工程（R：算法工程师；A：技术负责人；C：数据处理/文档；I：全员）
  - 模型训练与评估（R：算法工程师+负责人；A：负责人；C：分析/文档；I：全员）
  - 可视化与报告（R：数据分析师；A：负责人；C：文档工程师；I：全员）
  - 部署与演示（R：开发支持；A：负责人；C：分析/文档；I：全员）
- **协作流程**：需求澄清 → 方案评审 → 分工实施 → 周会复盘 → 质量门禁 → 汇报演练。
- **沟通机制**：周会+临时站会；统一任务看板；文档共编；代码 PR 评审；紧急问题 24h 兜底响应。
- **冲突与复盘**：以数据与指标为准绳；记录决策背景与替代方案；每周输出复盘纪要（问题-分析-改进）。
- **协作产出**：统一数据契约、图表风格规范、参数快照、可复现脚本，显著降低跨人协作摩擦。

---

## 14. 产出索引
- 模型与数据：`models/best_model.pkl`、`data/tfidf_matrix.npz`、`data/features_data.csv`
- 可视化：`photos/`、`results/` 下性能与分析图表
- 文档：`report/` 完整技术报告与执行摘要、`README.md`
- 运行：`main.py`、`run.py`、`requirements.txt`

---

## 15. 参考文献与学习资源
- 文献与资料（代表性）：
  - Manning, C. D., et al. Foundations of Statistical NLP（统计 NLP 基础）
  - scikit-learn 文档：`https://scikit-learn.org/stable/`
  - NLTK 书与文档：`https://www.nltk.org/`
  - TextStat 文档：`https://pypi.org/project/textstat/`
  - Kaggle: Human vs AI Generated Essays 数据页（数据许可与说明）
- 学习笔记与参数记录：随项目提交的报告与 JSON 参数快照。

---

## 16. 项目负责人方法与关键决策（新增）
- **负责人工作法**：
  - 路线图驱动：按“数据→特征→模型→评估→复现”推进，阶段出口设硬指标；
  - 证据优先：任何争议以小实验与指标说话，最小化空谈；
  - 成本意识：优先选择轻量、可解释、可复现的方案，再逐步引入更重表达；
  - 文档即产品：参数、日志、图表与结论均需留痕，便于审计与复现；
  - 提前兜底：关键节点指定替补，准备降级/旁路方案，保证按时交付。
- **关键决策与影响**：
  - 融合特征策略：显著提升边界样本稳健性（AUC +0.8pp，方差下降）；
  - 稀疏矩阵与序列化：降低团队设备门槛，减少复现失败；
  - 分层 5 折：评估更稳定，报告可信度提升；
  - 统一可视化规范：减少图表返工，提升汇报效率与专业度。

——
致谢：感谢团队成员在数据、算法、可视化与文档等环节的协作支持。通过本项目，我在特征工程、模型评估、工程化复现与学术表达方面得到系统训练，并形成可复用的文本检测项目方法论，为后续研究与应用奠定基础。