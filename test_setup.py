"""
æµ‹è¯•è„šæœ¬ - éªŒè¯é¡¹ç›®è®¾ç½®
"""

import os
import sys

def test_file_structure():
    """æµ‹è¯•æ–‡ä»¶ç»“æ„"""
    print("æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„...")
    
    required_files = [
        '01_data_exploration.py',
        '02_feature_engineering.py', 
        '03_model_training.py',
        '04_model_evaluation.py',
        'main.py',
        'requirements.txt',
        'README.md',
        'tasks.md',
        'ideas.md'
    ]
    
    missing_files = []
    for file in required_files:
        if os.path.exists(file):
            print(f"  âœ“ {file}")
        else:
            print(f"  âœ— {file}")
            missing_files.append(file)
    
    return len(missing_files) == 0

def test_data_directory():
    """æµ‹è¯•æ•°æ®ç›®å½•"""
    print("\næ£€æŸ¥æ•°æ®ç›®å½•...")
    
    data_dir = 'data'
    if not os.path.exists(data_dir):
        print(f"  âœ— æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        print("  è¯·åˆ›å»ºæ•°æ®ç›®å½•å¹¶æ”¾å…¥ balanced_ai_human_prompts.csv æ–‡ä»¶")
        return False
    
    print(f"  âœ“ æ•°æ®ç›®å½•å­˜åœ¨: {data_dir}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_file = os.path.join(data_dir, 'balanced_ai_human_prompts.csv')
    if os.path.exists(data_file):
        print(f"  âœ“ æ•°æ®æ–‡ä»¶å­˜åœ¨: {data_file}")
        return True
    else:
        print(f"  âœ— æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        print("  è¯·å°†æ•°æ®é›†æ–‡ä»¶æ”¾å…¥ data/ ç›®å½•ä¸­")
        return False

def test_imports():
    """æµ‹è¯•å¯¼å…¥"""
    print("\næµ‹è¯•Pythonæ¨¡å—å¯¼å…¥...")
    
    # æµ‹è¯•æ ‡å‡†åº“
    try:
        import os, sys, pickle, warnings
        print("  âœ“ æ ‡å‡†åº“å¯¼å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"  âœ— æ ‡å‡†åº“å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # æµ‹è¯•æ ¸å¿ƒä¾èµ–
    core_deps = ['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn']
    missing_deps = []
    
    for dep in core_deps:
        try:
            __import__(dep)
            print(f"  âœ“ {dep}")
        except ImportError:
            print(f"  âœ— {dep} (éœ€è¦å®‰è£…)")
            missing_deps.append(dep)
    
    # æµ‹è¯•å¯é€‰ä¾èµ–
    optional_deps = ['nltk', 'textstat', 'tqdm']
    missing_optional = []
    
    print("\næµ‹è¯•å¯é€‰ä¾èµ–...")
    for dep in optional_deps:
        try:
            __import__(dep)
            print(f"  âœ“ {dep}")
        except ImportError:
            print(f"  âš  {dep} (å¯é€‰ï¼Œæœªå®‰è£…)")
            missing_optional.append(dep)
    
    if missing_deps:
        print(f"\nç¼ºå°‘æ ¸å¿ƒä¾èµ–: {', '.join(missing_deps)}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False
    
    if missing_optional:
        print(f"\nå¯é€‰ä¾èµ–æœªå®‰è£…: {', '.join(missing_optional)}")
        print("æŸäº›åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨ï¼Œå»ºè®®å®‰è£…: pip install nltk textstat tqdm")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("Human vs AI Generated Essays é¡¹ç›®è®¾ç½®æµ‹è¯•")
    print("=" * 50)
    
    # æµ‹è¯•æ–‡ä»¶ç»“æ„
    files_ok = test_file_structure()
    
    # æµ‹è¯•æ•°æ®ç›®å½•
    data_ok = test_data_directory()
    
    # æµ‹è¯•å¯¼å…¥
    imports_ok = test_imports()
    
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœ:")
    print(f"  æ–‡ä»¶ç»“æ„: {'âœ“' if files_ok else 'âœ—'}")
    print(f"  æ•°æ®ç›®å½•: {'âœ“' if data_ok else 'âœ—'}")
    print(f"  ä¾èµ–å¯¼å…¥: {'âœ“' if imports_ok else 'âœ—'}")
    
    if files_ok and data_ok and imports_ok:
        print("\nğŸ‰ é¡¹ç›®è®¾ç½®å®Œæˆï¼Œå¯ä»¥å¼€å§‹è¿è¡Œï¼")
        print("\nè¿è¡Œå‘½ä»¤:")
        print("  python main.py                    # å®Œæ•´æµç¨‹")
        print("  python main.py --check-only       # ç¯å¢ƒæ£€æŸ¥")
        print("  python main.py --step data_exploration  # å•æ­¥éª¤è¿è¡Œ")
        return True
    else:
        print("\nâŒ é¡¹ç›®è®¾ç½®ä¸å®Œæ•´ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜")
        return False

if __name__ == "__main__":
    main()
